---
title: "HW2"
author: "Eric Xu"
date: "2025-09-23"
output: github_document
---
to store the local data files, and use relative paths to access these data files
`"./Data/"`
```{r setup, include = FALSE}
library(tidyverse)
```

## Problem 1
Data cleaning from csv files `snp` and `pol_month`, tidy and transpose the `unemployment` file
```{r Problem 1 data cleaning,message = FALSE}
pol_month = read_csv("./Data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon,sep = "-",
           into = c("year","month","day")) |> 
  mutate(
    year = as.integer(year),
    day = as.integer(day),
    month = as.integer(month),
    month = month.abb[month],
    president = case_when(prez_gop != 0 ~ "gop",
                          prez_dem != 0 ~ "dem")
    ) |> 
  select(-prez_gop, 
         -prez_dem, 
         -day
         )
snp = read_csv("./Data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date,
           sep = "/",
           into = c("month","day","year")) |> 
  mutate(
    year = as.integer(year),
    day = as.integer(day),
    month_num = as.integer(month),
    month = month.abb[month_num],
    year = case_when(
      year < 50 ~ 2000L + year,
      year >= 50 ~ 1900L + year
      )
    ) |> 
  select(year,month,everything()) |> 
  arrange(year,month_num)|> 
  select(-day,
         -month_num
         )

unemployment = read_csv("./Data/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    values_to = "unemployment_rate",
    names_to = "month" 
    ) |> 
  rename(
    year = Year
  )
```

merge data with the same year and month variable:
```{r data merge, message = FALSE}
joint = full_join(pol_month,snp, by = c("year","month")) |> 
  full_join(unemployment, by = c("year","month"))
```

__Descriptive data of `joint`:__
```{r plot and descriptive data}
skimr::skim(joint)
names(joint)

joint |> 
  ggplot(aes(x = year, y = unemployment_rate, color = president)) +
  geom_point(na.rm = TRUE) +
  labs(
    title = "Average Monthly Unemployment Rate Over Time",
    y = "Unemployment Rate (%)",
    x = "Year"
  ) +
  scale_x_continuous(n.breaks = 10)+
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    axis.title = element_text(size = 14, ),
    axis.text = element_text(size = 12)
    )

joint |> 
  ggplot(aes(x = year, y = close, color = president)) +
  geom_point(na.rm = TRUE) +
  labs(
    title = "S&P Closing Value over Time",
    x = "Year",
    y = "closing Values S&P"
  ) +  
  scale_x_continuous(n.breaks = 10)+
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    axis.title = element_text(size = 14, ),
    axis.text = element_text(size = 12)
    )
```

The dataset `joint` combines information from `pols-month`, `snp`, and `unemployment`. The original files tracked the partisan composition of U.S. politics from `r range(pol_month$year)[1]` to `r range(pol_month$year)[2]`, along with an indicator for the sitting president. The `snp` file contained monthly closing values of the S&P 500 stock index from `r range(snp$year)[1]` to `r range(snp$year)[2]`, the mean value is `r mean(as.numeric(joint$close), na.rm = TRUE)`, with a standard deviation of `r sd(joint$close, na.rm = TRUE)`. while the unemployment file provided national unemployment rates is `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]` by month. After cleaning and aligning by year and month, the merged dataset `joint` has `r dim(joint)[1]` rows and `r dim(joint)[2]` columns, covering the period `r range(joint$year)[1]` to `r range(joint$year)[2]`. On average, unemployment was `r mean(joint$unemployment_rate, na.rm = TRUE)`%, S&P closing values ranged within `r range(joint$close, na.rm = TRUE)[1]` and `r range(joint$close, na.rm = TRUE)[2]`. The overall diagram shows an increasing trend of unemployment rate and S&P closing value. The colored president political party demonstrated a fluctuation of closing value after 2000 and spiking of unemployment rate after 1980 when president is GOP. This data only shows association by time and president political party, and the association is not examined by other covariates. 

## Problem 2
```{r problem 2}
mr_trash_wheel = readxl::read_excel("./Data/202509 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel", range = "A2:N653")|>
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    trash_wheel = "Mr",
    year = as.integer(year)
    )

prof_trash_wheel = readxl::read_excel("./Data/202509 Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel", range = "A2:M120")|>
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(
    trash_wheel = "Professor",
    year = as.integer(year)
    )

gwyn_trash_wheel =  readxl::read_excel("./Data/202509 Trash Wheel Collection Data.xlsx",sheet = "Gwynns Falls Trash Wheel", range = "A2:L265")|>
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(
    trash_wheel = "Gwynnda",
    year = as.integer(year)
    )


all_wheel = bind_rows(mr_trash_wheel,prof_trash_wheel,gwyn_trash_wheel)

skimr::skim(all_wheel)


  
```
The combined Trash Wheel dataset contains `r nrow(all_wheel)` dumpster-level observations across Mr., Professor, and Gwynnda Trash Wheels. Variables include `r names(all_wheel)`, and item-specific counts such as `cigarette_butts`, `plastic_bottles`, and `sports_balls`. The variable `weight_tons` measures the amount of trash collected per dumpster, while `sports_balls` counts the number of balls collected at time, rounded to the nearest integer. Professor Trash Wheel has collected a total of `r sum(prof_trash_wheel$weight_tons, na.rm = TRUE)` tons of trash, while Gwynnda collected `r as.integer(sum(filter(gwyn_trash_wheel,year == 2022, month == "June")$cigarette_butts, na.rm = TRUE))` cigarette butts in June 2022.

## Problem 3
```{r problem3}
zip_code = read_csv("./Data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  select(zip_code,everything(),-file_date,-county_code,-county_fips,-state_fips)

zori = read.csv("./Data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  filter(region_type == "zip")|> 
  rename(
    zip_code = region_name,
    zori_county = county_name
         ) |> 
  select(zip_code,everything(),-region_type,-metro,-city,-state,-state_name,-region_id)

zori_long = zori |> 
  pivot_longer(x2015_01_31:x2024_08_31,
               names_to = "date",
               values_to = "zori",
               names_prefix = "x",
               )

zori_zip = inner_join(zori_long,zip_code,by="zip_code",relationship = "many-to-many")
```

```{r descriptive data}
skimr::skim(zori_zip)
dim(zori_zip)
unique(zori_zip$zip_code)
```
There are `r dim(zori_zip)[1]` observations as a long form of different date and rent index corresponding to neighborhood and zip code.
The data set included total of `r length(unique(zori_zip$zip_code))` zip codes as separate regions.

```{r descriptive data ZORI}
setdiff(zip_code$zip_code, zori$zip_code)
```

The zip codes above are not included in ZORI data with some possible situations that:

* few or no rental listings in database
* the region is commercial or non-residential
* privacy or insufficient sampling leads to not recorded region


**compare rental prices in January 2021 to prices in January 2020**
```{r COVID data}
zori_compare <- zori_zip  |> 
  filter(date %in% c("2020_01_31", "2021_01_31"))  |> 
  pivot_wider(names_from = date, values_from = zori)  |> 
  mutate(price_change = `2020_01_31` - `2021_01_31`)  |> 
  arrange(desc(price_change)) |> 
  slice(1:10) |> 
  select(zip_code, county,zori_county, neighborhood, `2020_01_31`, `2021_01_31`, price_change,neighborhood, county,)

knitr::kable(zori_compare)
```
The dataset `zori_compare` above demonstrates the 10 zip codes that have the greatest rental index drop during with the data recorded on date `2020_01_31` and `2021_01_31`. 
Lower Manhattan seems to have multiple neighborhoods on the list with a larger area of price dropping.The 10 areas are all in New York county with high concentrations of rental options. The price dropping is probably due to remote working and high living cost. 

